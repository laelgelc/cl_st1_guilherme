{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 1 - Guilherme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ad8a7-2d34-476b-be69-5d896b27d3ed",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1209cf-0515-45b3-8856-275ac692943e",
   "metadata": {},
   "source": [
    "Make sure the prerequisites in [CL_LMDA_prerequisites](https://github.com/laelgelc/laelgelc/blob/main/CL_LMDA_prerequisites.ipynb) are satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176abf37-6b08-47ca-a542-198d259060bb",
   "metadata": {},
   "source": [
    "### Additional prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df16305-d0bc-40b1-82f3-0145fb3de6f0",
   "metadata": {},
   "source": [
    "#### WebVTT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff70eb-fd2a-4194-bb29-585fa2c1f5c8",
   "metadata": {},
   "source": [
    "`webvtt-py` is a Python package for reading/writing WebVTT caption files.\n",
    "\n",
    "Please refer to:\n",
    "- [webvtt-py](https://pypi.org/project/webvtt-py/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc54997-f65c-4c4e-8717-1adc576cdab9",
   "metadata": {},
   "source": [
    "##### Installing `webvtt-py` on Anacoda Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a979cb-9445-4128-9b42-8335bc57b644",
   "metadata": {},
   "source": [
    "As `webvtt-py` is not available in any of the conda channels, the following procedure should be followed on `Anaconda Prompt` to install it in the required environment, in this case `Env20240401`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d8482-ffa6-47b9-842f-525d09acfbda",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Replace `Env20240401` by your actual environment name"
   ]
  },
  {
   "cell_type": "raw",
   "id": "397f091e-9005-41d9-a8e5-d54e652eb1cf",
   "metadata": {},
   "source": [
    "(base) C:\\Users\\eyamr>conda env list\n",
    "# conda environments:\n",
    "#\n",
    "base                  *  C:\\Users\\eyamr\\anaconda3\n",
    "Env20240401              C:\\Users\\eyamr\\anaconda3\\envs\\Env20240401\n",
    "\n",
    "\n",
    "(base) C:\\Users\\eyamr>conda activate Env20240401\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>pip3 install webvtt-py\n",
    "<omitted>\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>pip3 freeze\n",
    "<omitted>\n",
    "webvtt-py==0.5.0\n",
    "<omitted>\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>conda deactivate\n",
    "\n",
    "(base) C:\\Users\\eyamr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d5093-a79a-4c09-bd1c-4220c40b90e6",
   "metadata": {},
   "source": [
    "## WebVTT proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b359393-764d-47f7-bfa0-fb736be47cc1",
   "metadata": {},
   "source": [
    "Please refer to:\n",
    "- [CL_webvtt-py_Extraction](https://github.com/laelgelc/laelgelc/blob/main/CL_webvtt-py_Extraction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6c3de-c437-4675-826e-75759ea4d970",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbee987-981e-4e35-9c99-63cbcb132bd6",
   "metadata": {},
   "source": [
    "Please download the following dataset (Right-click on the link and choose `Open link in a new tab` to download the corresponding file):\n",
    "- [cl_st1_guilherme-dataset.zip](https://pucsp-my.sharepoint.com/:u:/g/personal/ra00341729_pucsp_edu_br/EazB9wcuMSNEuxenV9Nb78ABGT8YTV0kwQJFgFymEDwhRA?e=PATjQW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5ac9f-49c4-459b-a6a5-91864c30c659",
   "metadata": {},
   "source": [
    "Extract the .zip file in the directory where this Jupyter Notebook is being executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c3a80-3acb-41e3-8fae-eb855afac90c",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b97929e-c64a-4e9e-8cba-ce5765f0f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webvtt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938ddf6-1b87-4125-9548-6b874727b35b",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed9e600-411c-4088-a109-544680df9d5d",
   "metadata": {},
   "source": [
    "### Defining the input and output directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e143317-88a1-4740-8913-741748b478a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'cl_st1_guilherme-dataset'\n",
    "output_directory = input_directory + '-output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e077f8ba-37be-4336-b5a6-67cde82a46a4",
   "metadata": {},
   "source": [
    "### Defining a function to extract caption texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0890ec98-0e9f-491a-b112-3f52433e9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_caption_text(webvtt_file, caption_file):\n",
    "    vtt = webvtt.read(webvtt_file)\n",
    "    \n",
    "    # Writing the text of the caption to the output file\n",
    "    with open(caption_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('text' + '\\n') # Includes the header that will be used in the dataframe\n",
    "        for caption in vtt:\n",
    "            f.write(caption.text + '\\n')\n",
    "    \n",
    "    # Deduplicating the text of the caption using a dataframe\n",
    "    df = pd.read_table(caption_file)\n",
    "    df['text'] = df['text'].map(str)\n",
    "    df.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Creating a single string containing all 'text' values separated by spaces\n",
    "    text_line = ' '.join(df['text'])\n",
    "\n",
    "    # Rewriting the output file with the single string\n",
    "    with open(caption_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(text_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea964e0-7939-462d-b89b-172510dfcb81",
   "metadata": {},
   "source": [
    "### Defining a function to recursively process the `input_directory` and store the results in `output_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990dca26-1853-4ea5-b19d-cb07e836392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(input_directory, output_directory):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.vtt'):\n",
    "                # Constructing the corresponding caption filename\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                caption_filename = base_name + '.txt'\n",
    "\n",
    "                # Creating the output subdirectory structure\n",
    "                relative_path = os.path.relpath(root, input_directory)\n",
    "                output_subdir = os.path.join(output_directory, relative_path)\n",
    "                os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "                # Full paths for input and output files\n",
    "                input_file_path = os.path.join(root, filename)\n",
    "                output_file_path = os.path.join(output_subdir, caption_filename)\n",
    "\n",
    "                # Calling 'extract_caption_text' function\n",
    "                extract_caption_text(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740705b7-6f5f-479e-99b3-99f6ecf30257",
   "metadata": {},
   "source": [
    "### Processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c111341-7b5a-4198-a5bc-aee205c81129",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_directory(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242a2e6-0f3c-49f8-a409-a2eac9be4173",
   "metadata": {},
   "source": [
    "### Importing the texts into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d341e269-03f9-4532-9184-43ae7c16546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_contents(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f'Error reading file {file_path}: {e}')\n",
    "        return None\n",
    "\n",
    "def process_output_directory(output_directory):\n",
    "    # Initialize an empty list to store data\n",
    "    data = []\n",
    "\n",
    "    # Recursively iterate through the output_directory\n",
    "    for root, _, files in os.walk(output_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            file_contents = read_file_contents(file_path)\n",
    "            if file_contents is not None:\n",
    "                data.append({'text': file_contents, 'filepath': file_path})\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Importing the texts into the dataframe 'df_tweets_filtered'. Even though this study does not relate to 'tweets', this dataframe name is adopted in order to enable code reuse in subsequent processing stages\n",
    "df_tweets_filtered = process_output_directory(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b3c2334-eef2-4b8f-8b03-423f219eb533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e a Bíblia é a verdade absoluta é a palavra de...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e eu não vou me calar por uma série de coisas ...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eu vou dizer uma coisa para você que ele faz e...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e decida salvar seu casamento sabe por quê Por...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e você vai ter que lutar para receber as prome...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MOTIVACIONAL P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>a visão correta da vida você tem que ter um ol...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>conseguiu garantir só você tem que entender al...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>é o desafio de vencer a nossa natureza a chama...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>características de quem quer produzir obras de...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Considere isso que eu vou te falar sobre a que...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     e a Bíblia é a verdade absoluta é a palavra de...   \n",
       "1     e eu não vou me calar por uma série de coisas ...   \n",
       "2     eu vou dizer uma coisa para você que ele faz e...   \n",
       "3     e decida salvar seu casamento sabe por quê Por...   \n",
       "4     e você vai ter que lutar para receber as prome...   \n",
       "...                                                 ...   \n",
       "1821  a visão correta da vida você tem que ter um ol...   \n",
       "1822  conseguiu garantir só você tem que entender al...   \n",
       "1823  é o desafio de vencer a nossa natureza a chama...   \n",
       "1824  características de quem quer produzir obras de...   \n",
       "1825  Considere isso que eu vou te falar sobre a que...   \n",
       "\n",
       "                                               filepath  \n",
       "0     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "1     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "2     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "3     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "4     cl_st1_guilherme-dataset-output/MOTIVACIONAL P...  \n",
       "...                                                 ...  \n",
       "1821  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1822  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1823  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1824  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1825  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "\n",
       "[1826 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e4eac3-e506-40ed-b509-cad997fd066e",
   "metadata": {},
   "source": [
    "### Dropping duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d965be-50fb-4669-9922-0eaaf152c101",
   "metadata": {},
   "source": [
    "#### Duplicate texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7426b0d-5cf7-4205-aca4-7fcd302af079",
   "metadata": {},
   "source": [
    "Checking for identical texts in terms of content of the column `text` in order to eliminate duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0932955f-9a94-4aed-8f45-d63cd26c1296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)\n",
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8333e700-315e-4eab-9400-897fc75caabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e a Bíblia é a verdade absoluta é a palavra de...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e eu não vou me calar por uma série de coisas ...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eu vou dizer uma coisa para você que ele faz e...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e decida salvar seu casamento sabe por quê Por...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e você vai ter que lutar para receber as prome...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MOTIVACIONAL P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>a visão correta da vida você tem que ter um ol...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>conseguiu garantir só você tem que entender al...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>é o desafio de vencer a nossa natureza a chama...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>características de quem quer produzir obras de...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>Considere isso que eu vou te falar sobre a que...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1811 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     e a Bíblia é a verdade absoluta é a palavra de...   \n",
       "1     e eu não vou me calar por uma série de coisas ...   \n",
       "2     eu vou dizer uma coisa para você que ele faz e...   \n",
       "3     e decida salvar seu casamento sabe por quê Por...   \n",
       "4     e você vai ter que lutar para receber as prome...   \n",
       "...                                                 ...   \n",
       "1806  a visão correta da vida você tem que ter um ol...   \n",
       "1807  conseguiu garantir só você tem que entender al...   \n",
       "1808  é o desafio de vencer a nossa natureza a chama...   \n",
       "1809  características de quem quer produzir obras de...   \n",
       "1810  Considere isso que eu vou te falar sobre a que...   \n",
       "\n",
       "                                               filepath  \n",
       "0     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "1     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "2     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "3     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "4     cl_st1_guilherme-dataset-output/MOTIVACIONAL P...  \n",
       "...                                                 ...  \n",
       "1806  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1807  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1808  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1809  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1810  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "\n",
       "[1811 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee3767-aec7-45d2-8ccc-6d1f75699c85",
   "metadata": {},
   "source": [
    "### Inspecting a few tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52ca4ba7-cc04-4ccf-9bc7-2d8a126b9139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:o povo abençoado do Brasil inacreditável absurdo dos Absurdos uma juíza do Rio Grande do Sul na Lúcia resolveu que a partir da abertura oficial da campanha eleitoral é proibido usar a bandeira do Brasil porque eu tô envolvido com ela o verde e amarelo porque representa um lado ela quer apareceu não tem nada que fazer é petista Unidos onde um povo é nacionalista tá usa a Americana esquerda comunista É por isso agora aqui no Brasil parte da Europa e na América Latina esquerda influenciada pela esquerda comunista por isso que eles usam vermelho bolsonaro trouxe de volta ao brasileiro nacionalismo que o PT apagou Então as manifestações motor ciata Onde bolsonaro vai de maneira espontânea o povo leva E aí essas imagens agora onde Rua Vital PT que vai ser cinismo para enganar mais uma vez o povo que eles usam vermelho que para ele aí deu orgia para cima da Nação de seu símbolo Vocês estão vendo aí eles usam vermelho o vermelho representa a bandeira comunista aqui ó Foi não é daqui a foice eo martelo com essa porcaria aqui a gente vai esse aqui ó ó rasca e joga no lixo não é prata cá as pessoas que usam vermelho nós temos que aprender a respeitar as pessoas mas isso aí é lixo essa aqui não essa aqui nos representa isso aqui é nacionalismo isso aqui é Brasil que nós amamos a nossa bandeira jamais será vermelha eu vou terminar o meu vídeo mostrando uma fala do presidente que eu concordo o grau escuros Brasil acima de tudo Deus acima de todos E aí\n"
     ]
    }
   ],
   "source": [
    "inspected_row = 1277\n",
    "print('text:' + df_tweets_filtered.loc[inspected_row, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb2127-3485-402c-aae0-95f4b8499ee2",
   "metadata": {},
   "source": [
    "## Exporting to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113c53e-bdf4-4653-a90c-2a47fc655b65",
   "metadata": {},
   "source": [
    "### JSONL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04efc496-8304-4b3d-ba91-64ffbc21728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text', 'filepath']].to_json('tweets_filtered.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61bbba5-4057-40b7-b53b-29ba7f97526f",
   "metadata": {},
   "source": [
    "### TSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eadf6dc2-69dc-41e9-831f-618b8b0dbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text', 'filepath']].to_csv('tweets_filtered.tsv', sep='\\t', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e97d4-9152-4ce9-a323-30b3a4ac2efd",
   "metadata": {},
   "source": [
    "## Importing the Target Corpus into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f6bcc09-02d9-4e0c-a121-340cbf6b2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered = pd.read_json('tweets_filtered.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f998f3-6582-4b4d-8bfe-3e46be722878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e a Bíblia é a verdade absoluta é a palavra de...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e eu não vou me calar por uma série de coisas ...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eu vou dizer uma coisa para você que ele faz e...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e decida salvar seu casamento sabe por quê Por...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e você vai ter que lutar para receber as prome...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MOTIVACIONAL P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  e a Bíblia é a verdade absoluta é a palavra de...   \n",
       "1  e eu não vou me calar por uma série de coisas ...   \n",
       "2  eu vou dizer uma coisa para você que ele faz e...   \n",
       "3  e decida salvar seu casamento sabe por quê Por...   \n",
       "4  e você vai ter que lutar para receber as prome...   \n",
       "\n",
       "                                            filepath  \n",
       "0  cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "1  cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "2  cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "3  cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "4  cl_st1_guilherme-dataset-output/MOTIVACIONAL P...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7fc1c49-1884-4650-a159-b9b3f3f842cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f73199-776b-4d85-8ecd-2673b634f5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        object\n",
       "filepath    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e743b0db-02a0-4e0b-b0b5-d6659960bc30",
   "metadata": {},
   "source": [
    "## Replacing the `pipe` character by the `-` character in the `text` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc943030-7448-4d4d-98b8-b03c40e113e2",
   "metadata": {},
   "source": [
    "Further on, a few columns of the dataframe are going to be exported into the file `tweets.txt` whose columns need to be delimited by the `pipe` character. Therefore, it is recommended that any occurrences of the `pipe` character in the `text` column are replaced by another character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab1c3584-ae80-41fc-b03a-4286a564a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace the 'pipe' character by the '-' character\n",
    "def replace_pipe_with_hyphen(input_string):\n",
    "    modified_string = re.sub(r'\\|', '-', input_string)\n",
    "    return modified_string\n",
    "\n",
    "# Replacing the 'pipe' character by the '-' character\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(replace_pipe_with_hyphen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d28f3-7d63-4c02-ba55-0dbc957a4291",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bed48e1-c6f3-49af-966b-bdb81183d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text']].to_csv('tweets_emojified1.tsv', sep='\\t', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d4ca4-2999-47d3-ae97-b4f3a7599d84",
   "metadata": {},
   "source": [
    "## Tokenising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f950bc7-9ffa-4d96-9ce0-439643f90a55",
   "metadata": {},
   "source": [
    "Please refer to [What is tokenization in NLP?](https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c1d393e-e85d-48f8-93f2-d7dfec6a2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to tokenise a string\n",
    "def tokenise_string(input_line):\n",
    "    # Replace URLs with placeholders\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\b'\n",
    "    placeholder = '<URL>'  # Choose a unique placeholder\n",
    "    urls = re.findall(url_pattern, input_line)\n",
    "    tokenised_line = re.sub(url_pattern, placeholder, input_line)  # Replace URLs with placeholders\n",
    "    \n",
    "    # Replace curly quotes with straight ones\n",
    "    tokenised_line = tokenised_line.replace('“', '\"').replace('”', '\"').replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "    # Separate common punctuation marks with spaces\n",
    "    tokenised_line = re.sub(r'([.\\!?,\"\\'/()])', r' \\1 ', tokenised_line)\n",
    "    # Add a space before '#'\n",
    "    tokenised_line = re.sub(r'(?<!\\s)#', r' #', tokenised_line)  # Add a space before '#' if it is not already preceded by one\n",
    "    # Reduce extra spaces by a single space\n",
    "    tokenised_line = re.sub(r'\\s+', ' ', tokenised_line)\n",
    "    \n",
    "    # Replace the placeholders with the respective URLs\n",
    "    for url in urls:\n",
    "        tokenised_line = tokenised_line.replace(placeholder, url, 1)\n",
    "    \n",
    "    return tokenised_line\n",
    "\n",
    "# Tokenising the strings\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(tokenise_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d523fd73-2c9c-4481-92cc-290de7dd57c6",
   "metadata": {},
   "source": [
    "## Creating the files `file_index.txt` and `tweets.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368c6b3-5650-4a79-971b-bde873615a39",
   "metadata": {},
   "source": [
    "### Creating column `text_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55c76a37-1702-4c6c-83ac-9bef08c6b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['text_id'] = 't' + df_tweets_filtered.index.astype(str).str.zfill(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa282811-780f-4ab6-8eff-3e084d001827",
   "metadata": {},
   "source": [
    "### Creating column `conversation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ae013ab-6d27-41dc-83c9-6a289221c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['conversation'] = 'v:' + df_tweets_filtered['filepath']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46105d2-d49d-44a7-a681-0749d5c69bfb",
   "metadata": {},
   "source": [
    "#### Replacing space by the `_` character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aaa0ca-b8b0-4270-add3-939091f3a499",
   "metadata": {},
   "source": [
    "**Important**: Since the strings in the original columns contain spaces, Pandas creates `file_index.txt` with the columns enclosed with `\"` - this caracter causes issues in `examples.sh` when it is executed. Therefore, spaces should be replaced by another character such as underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1738396-c2fa-4662-987e-4a2fcb4b8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace space by the '_' character\n",
    "def replace_space_with_underscore(input_string):\n",
    "    modified_string = re.sub(r' ', '_', input_string)\n",
    "    return modified_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fb89544-e8bf-4ac3-8b36-8af282da5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing space by the '_' character\n",
    "df_tweets_filtered['conversation'] = df_tweets_filtered['conversation'].apply(replace_space_with_underscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5bafa-10e7-4153-8e7a-7fe04b2c4b0a",
   "metadata": {},
   "source": [
    "### Creating column `date`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c6012-9522-4f18-a53d-c6f917eec84b",
   "metadata": {},
   "source": [
    "The date for all texts are defined as the date Guilherme sent the dataset, 16th April, 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0baabff7-0f46-4d02-9073-618e6ade8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['date'] = 'd:' + '2024-04-16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a8832-8610-4203-96d2-13e907449491",
   "metadata": {},
   "source": [
    "### Creating column `text_url`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f712f487-0bef-4a55-8797-7db10d805be6",
   "metadata": {},
   "source": [
    "No URL was considered for all texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a01cbe8-44e4-468a-b88f-6e2d62d9c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['text_url'] = 'url:' + 'no_url'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35df8ab5-4221-4f05-a231-98f20c743e80",
   "metadata": {},
   "source": [
    "### Creating column `user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ad1d1-a46b-402e-bd15-9b74f9ab31a5",
   "metadata": {},
   "source": [
    "`silas_malafaia` was considered for all texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "931df388-ee75-4b39-9a6f-3142948dbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['user'] = 'u:' + 'silas_malafaia'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c05b877-23b8-4f3c-a6c1-285c6b243645",
   "metadata": {},
   "source": [
    "### Creating column `content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad9ced8b-bb05-4c59-8ae7-170ba337a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['content'] = 'c:' + df_tweets_filtered['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb9068-c3a5-41cc-a25c-a91b341778e9",
   "metadata": {},
   "source": [
    "### Reordering the created columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fe944-8293-49ee-b40a-c2472e6b6181",
   "metadata": {},
   "source": [
    "Please refer to:\n",
    "- [Python - List Comprehension 1](https://www.w3schools.com/python/python_lists_comprehension.asp)\n",
    "- [Python - List Comprehension 2](https://treyhunner.com/2015/12/python-list-comprehensions-now-in-color/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2f1c5e1-d748-45cc-9697-802e90c8ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns (we use list comprehension to create a list of all columns except 'text_id', 'variable', 'date' and 'text_url')\n",
    "df_tweets_filtered = df_tweets_filtered[['text_id', 'conversation', 'date', 'text_url', 'user', 'content'] + [col for col in df_tweets_filtered.columns if col not in ['text_id', 'conversation', 'date', 'text_url', 'user', 'content']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd049019-2e68-4859-828a-cd15f27e24c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>conversation</th>\n",
       "      <th>date</th>\n",
       "      <th>text_url</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t000000</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MALAFAIA_RES...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:e a Bíblia é a verdade absoluta é a palavra ...</td>\n",
       "      <td>e a Bíblia é a verdade absoluta é a palavra de...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t000001</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MALAFAIA_RES...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:e eu não vou me calar por uma série de coisa...</td>\n",
       "      <td>e eu não vou me calar por uma série de coisas ...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t000002</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MALAFAIA_RES...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:eu vou dizer uma coisa para você que ele faz...</td>\n",
       "      <td>eu vou dizer uma coisa para você que ele faz e...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t000003</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MALAFAIA_RES...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:e decida salvar seu casamento sabe por quê P...</td>\n",
       "      <td>e decida salvar seu casamento sabe por quê Por...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MALAFAIA RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t000004</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MOTIVACIONAL...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:e você vai ter que lutar para receber as pro...</td>\n",
       "      <td>e você vai ter que lutar para receber as prome...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MOTIVACIONAL P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>t001806</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:a visão correta da vida você tem que ter um ...</td>\n",
       "      <td>a visão correta da vida você tem que ter um ol...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>t001807</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:conseguiu garantir só você tem que entender ...</td>\n",
       "      <td>conseguiu garantir só você tem que entender al...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>t001808</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:é o desafio de vencer a nossa natureza a cha...</td>\n",
       "      <td>é o desafio de vencer a nossa natureza a chama...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>t001809</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:características de quem quer produzir obras ...</td>\n",
       "      <td>características de quem quer produzir obras de...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>t001810</td>\n",
       "      <td>v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:Considere isso que eu vou te falar sobre a q...</td>\n",
       "      <td>Considere isso que eu vou te falar sobre a que...</td>\n",
       "      <td>cl_st1_guilherme-dataset-output/MINUTOS DE VIT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1811 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_id                                       conversation  \\\n",
       "0     t000000  v:cl_st1_guilherme-dataset-output/MALAFAIA_RES...   \n",
       "1     t000001  v:cl_st1_guilherme-dataset-output/MALAFAIA_RES...   \n",
       "2     t000002  v:cl_st1_guilherme-dataset-output/MALAFAIA_RES...   \n",
       "3     t000003  v:cl_st1_guilherme-dataset-output/MALAFAIA_RES...   \n",
       "4     t000004  v:cl_st1_guilherme-dataset-output/MOTIVACIONAL...   \n",
       "...       ...                                                ...   \n",
       "1806  t001806  v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...   \n",
       "1807  t001807  v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...   \n",
       "1808  t001808  v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...   \n",
       "1809  t001809  v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...   \n",
       "1810  t001810  v:cl_st1_guilherme-dataset-output/MINUTOS_DE_V...   \n",
       "\n",
       "              date    text_url              user  \\\n",
       "0     d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "1     d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "2     d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "3     d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "4     d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "...            ...         ...               ...   \n",
       "1806  d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "1807  d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "1808  d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "1809  d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "1810  d:2024-04-16  url:no_url  u:silas_malafaia   \n",
       "\n",
       "                                                content  \\\n",
       "0     c:e a Bíblia é a verdade absoluta é a palavra ...   \n",
       "1     c:e eu não vou me calar por uma série de coisa...   \n",
       "2     c:eu vou dizer uma coisa para você que ele faz...   \n",
       "3     c:e decida salvar seu casamento sabe por quê P...   \n",
       "4     c:e você vai ter que lutar para receber as pro...   \n",
       "...                                                 ...   \n",
       "1806  c:a visão correta da vida você tem que ter um ...   \n",
       "1807  c:conseguiu garantir só você tem que entender ...   \n",
       "1808  c:é o desafio de vencer a nossa natureza a cha...   \n",
       "1809  c:características de quem quer produzir obras ...   \n",
       "1810  c:Considere isso que eu vou te falar sobre a q...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     e a Bíblia é a verdade absoluta é a palavra de...   \n",
       "1     e eu não vou me calar por uma série de coisas ...   \n",
       "2     eu vou dizer uma coisa para você que ele faz e...   \n",
       "3     e decida salvar seu casamento sabe por quê Por...   \n",
       "4     e você vai ter que lutar para receber as prome...   \n",
       "...                                                 ...   \n",
       "1806  a visão correta da vida você tem que ter um ol...   \n",
       "1807  conseguiu garantir só você tem que entender al...   \n",
       "1808  é o desafio de vencer a nossa natureza a chama...   \n",
       "1809  características de quem quer produzir obras de...   \n",
       "1810  Considere isso que eu vou te falar sobre a que...   \n",
       "\n",
       "                                               filepath  \n",
       "0     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "1     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "2     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "3     cl_st1_guilherme-dataset-output/MALAFAIA RESPO...  \n",
       "4     cl_st1_guilherme-dataset-output/MOTIVACIONAL P...  \n",
       "...                                                 ...  \n",
       "1806  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1807  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1808  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1809  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "1810  cl_st1_guilherme-dataset-output/MINUTOS DE VIT...  \n",
       "\n",
       "[1811 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595209f2-7232-44fd-9cae-8f390da0144d",
   "metadata": {},
   "source": [
    "### Creating the file `file_index.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f142562-c04f-4f6e-9bee-d0687762397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text_id', 'conversation', 'date', 'text_url']].to_csv('file_index.txt', sep=' ', index=False, header=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8f5f1-a8ff-4eda-9c71-f47aef7020e0",
   "metadata": {},
   "source": [
    "### Creating the file `tweets.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9548bb29-9cd1-46cd-9707-0cc004e84899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder tweets created!\n"
     ]
    }
   ],
   "source": [
    "folder = 'tweets'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "    print(f'Folder {folder} created!')\n",
    "except FileExistsError:\n",
    "    print(f'Folder {folder} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aaaa41-ca4e-4102-95dc-ccdf589fed9a",
   "metadata": {},
   "source": [
    "Note: The parameters `doublequote=False` and `escapechar=' '` are required to avoid that the column content is doublequoted with '\"' in sentences that use characters that need to be escaped such as double quote '\"' itself - this causes a malformed response from TreeTagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca8211a3-ea0d-45b8-a911-bc178b703a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text_id', 'conversation', 'date', 'user', 'content']].to_csv(f'{folder}/tweets.txt', sep='|', index=False, header=False, encoding='utf-8', lineterminator='\\n', doublequote=False, escapechar=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f769843-4ff9-4436-a2e0-d61e2c391e9d",
   "metadata": {},
   "source": [
    "## Tagging with TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3877be9-6317-42ee-8e8d-c15c48f77996",
   "metadata": {},
   "source": [
    "- On Visual Studio Code (VS Code), open the folder where your project is located with `Open Folder...`\n",
    "- Open a WSL Ubuntu Terminal on VS Code\n",
    "- **Important**: Activate the `my_env` Python environment by executing `source \"$HOME\"/my_env/bin/activate`\n",
    "- Proceed as indicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720724ab-5e77-4e9e-b05a-24cf73259cd0",
   "metadata": {},
   "source": [
    "Purpose: Annotate the texts in `tweets/tweets.txt` with part-of-speech and lemma information.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `tweets/tweets.txt`\n",
    "- Output\n",
    "    - `tweets/tagged.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005cc09-f5ef-454f-9b74-4d7ca9fe4f10",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash treetagging.sh\n",
    "--- treetagging t000000 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000001 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000002 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000003 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "<omitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd8318-f880-49d8-8f24-eb8db0435489",
   "metadata": {},
   "source": [
    "## Processing `CL_St1_Ph11_Guilherme.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad236d6-1810-417c-a15f-eb27709bab68",
   "metadata": {},
   "source": [
    "Run the solution `CL_St1_Ph11_Guilherme.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0060ba-d01c-4e48-a353-8c9ba0fc456e",
   "metadata": {},
   "source": [
    "## Processing `tokenstypes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93351bf2-3457-4b47-8a47-7ff13c4e0e1a",
   "metadata": {},
   "source": [
    "Purpose: Capture the content tokens (specific occurrences of words) and the content types (general concept of words) from `tweets/tagged.txt`.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `tweets/tagged.txt`\n",
    "- Output\n",
    "    - `tweets/tokens.txt`\n",
    "    - `tweets/types.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddc717-8ff2-4f38-ae10-8d6616de6a6c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash tokenstypes.sh\n",
    "--- tokenstypes t000000 / 18206 ---\n",
    "--- tokenstypes t000001 / 18206 ---\n",
    "--- tokenstypes t000002 / 18206 ---\n",
    "--- tokenstypes t000003 / 18206 ---\n",
    "--- tokenstypes t000004 / 18206 ---\n",
    "--- tokenstypes t000005 / 18206 ---\n",
    "<omitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef598329-fb5a-4b07-8799-b2bbb55847f1",
   "metadata": {},
   "source": [
    "## Processing `toplemmas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce5796-0434-44d5-88e2-8f934a6cebc8",
   "metadata": {},
   "source": [
    "Purpose: Determine the 1.000 top lemmas. **Important**: This process requires manual inspection. Non-meaningful lemmas should be excluded by updating `stoplist.sed` and reiterating the processing.\n",
    "- Input\n",
    "    - `tweets/types.txt`\n",
    "    - `stoplist.sed`: List of rules that allows the exclusion of a certain lemmas\n",
    "- Output\n",
    "    - `selectedwords` = `var_index.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0fc8e-73e2-4e2d-9e2f-73068e4132fc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash toplemmas.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a4675-5067-4e8b-8ca8-baf9f1b915c1",
   "metadata": {},
   "source": [
    "## Processing `sas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d158b2-73d7-477e-a7a7-2b87216a19ae",
   "metadata": {},
   "source": [
    "Purpose: Prepare input data for processing in SAS.\n",
    "- Input\n",
    "    - `tweets/types.txt`\n",
    "    - `selectedwords`\n",
    "    - `file_index.txt`\n",
    "- Output\n",
    "    - `columns`\n",
    "    - `sas/data.txt`\n",
    "    - `sas/dates.txt`\n",
    "    - `sas/wcount.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d250d29-861c-41a6-9793-e0df758100e0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash sas.sh\n",
    "--- v000001 ---\n",
    "--- v000002 ---\n",
    "--- v000003 ---\n",
    "--- v000004 ---\n",
    "--- v000005 ---\n",
    "<omitted>\n",
    "--- v001000 ---\n",
    "[nltk_data] Downloading package punkt to /home/eyamrog/nltk_data...\n",
    "[nltk_data]   Package punkt is already up-to-date!\n",
    "Word counts written to sas/wcount.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8087ea-ffd4-43b9-8eda-4444b931c319",
   "metadata": {},
   "source": [
    "## Processing `datamatrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4374f48-04b6-48af-a31d-125ef0e85972",
   "metadata": {},
   "source": [
    "Purpose: Prepares input data for calculating the correlation matrix.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `columns`\n",
    "    - `selectedwords`\n",
    "- Output\n",
    "    - `file_ids.txt`\n",
    "    - `data.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23925f09-05ef-44a5-ba48-78cac1dedc76",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash datamatrix.sh\n",
    "--- v000001 ---\n",
    "--- v000002 ---\n",
    "--- v000003 ---\n",
    "--- v000004 ---\n",
    "--- v000005 ---\n",
    "<omitted>\n",
    "--- v001000 ---\n",
    "--- data.csv ...---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130e8f0-a7e5-4f6e-b427-090f7cda4856",
   "metadata": {},
   "source": [
    "## Processing `correlationmatrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddbb87-b4de-4c41-8177-b2f677d803b6",
   "metadata": {},
   "source": [
    "Purpose: Calculates the correlation matrix.\n",
    "- Input\n",
    "    - `data.csv`\n",
    "- Output\n",
    "    - `correlation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42927846-5d87-4f5f-8ce6-8beb4ef733a4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash correlationmatrix.sh\n",
    "--- python correlation ... ---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9203f-e9e1-4a73-8bed-7dec1ad8617e",
   "metadata": {},
   "source": [
    "## Processing `formats`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69517100-c28d-44ba-90a7-37988e3df8ad",
   "metadata": {},
   "source": [
    "Purpose: Prepare input data for processing in SAS.\n",
    "- Input\n",
    "    - `data.csv`\n",
    "    - `selectedwords`\n",
    "- Output\n",
    "    - `sas/corr.txt`\n",
    "    - `sas/word_labels_format.sas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9b02f-fd33-4ff2-bf57-463fac9743e6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash formats.sh\n",
    "--- sas/sas/corr.txt ---\n",
    "--- sas/word_labels_format.sas ---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322cbac-cd18-4420-a4b1-6bdcab8d880e",
   "metadata": {},
   "source": [
    "## Processing the statistical procedures on SAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e61189-3aa3-4d7a-b8f2-ca9e78465ddc",
   "metadata": {},
   "source": [
    "- Log in to your [SAS OnDemand for Academics](https://welcome.oda.sas.com/) account\n",
    "- Proceed as indicated in this [video tutorial](https://youtu.be/I3u9zD3jyOA?si=68uIKVc2iusGG2KY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d656a17-6cc2-409a-8cc0-b500a11b2581",
   "metadata": {},
   "source": [
    "## Processing `examples`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe92f1-8083-46d7-b31d-1c43c35fe488",
   "metadata": {},
   "source": [
    "Purpose: Extract examples for analysis.\n",
    "- Input\n",
    "    - `sas/output_\"$project\"/loadtable.html`\n",
    "    - `sas/output_\"$project\"/\"$project\"_scores.tsv`\n",
    "    - `sas/output_\"$project\"/\"$project\"_scores_only.tsv`\n",
    "- Output\n",
    "    - `examples/factors`\n",
    "    - `example files`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530850e1-a9ba-43f8-b542-ad5a0e3a4534",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash examples.sh\n",
    "6780\n",
    "1246\n",
    "698\n",
    "123\n",
    "--- examples f1pos ---\n",
    "--- factor 1 pos # 000001 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000002 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000003 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000004 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000005 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "<ommitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38617b-0487-4ba2-b619-d9b78aba9f2c",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf501e4a-1193-4999-bdc0-88c08d2840f7",
   "metadata": {},
   "source": [
    "Right-click on the link and choose `Open link in a new tab` to download the corresponding file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73ba45-9d6c-4578-b14e-c80c3ccaafe4",
   "metadata": {},
   "source": [
    "- [CL_St1_Querem_Results.zip](https://pucsp-my.sharepoint.com/:u:/g/personal/ra00341729_pucsp_edu_br/ERbP8OEqscBJlh4l6s6_UFgBTUGtnR6PDI1NXZwVBh6Dyg?e=W8YXpq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb169464-4f29-4513-b272-46f201deff17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
